{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e4d281-66fd-42a6-8402-a2710b79a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import implicit\n",
    "from gensim.models import word2vec\n",
    "from tqdm.auto import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import joblib\n",
    "\n",
    "import feature_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5051993-f6e0-47ec-bebe-c89c39b90416",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('data/')\n",
    "converted_data_path = data_root / 'data_converted'\n",
    "features_dir = Path('user_features/')\n",
    "features_root = Path('feature_transformers/')\n",
    "embeddings_dir = Path('embeddings')\n",
    "\n",
    "n_urls = 199683\n",
    "n_users = 415317\n",
    "\n",
    "domains_numerator = feature_utils.CatNumerator.load('feature_transformers/url_host.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d092666b-6a43-44c5-b2e1-32b12fadb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line(line):\n",
    "    return list(map(int, line.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd2336d-eb33-496f-8cf3-1c91a84ed48a",
   "metadata": {},
   "source": [
    "# Histories preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b2137-86cb-46d5-ad46-f4fcdfa10aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_histories = [[] for _ in range(n_users)]\n",
    "\n",
    "def _add_history(x):\n",
    "    users_histories[x['user_id'].values[0]] = list(x['url_host'])\n",
    "\n",
    "for p in tqdm(list(converted_data_path.iterdir())):\n",
    "    ds_part = pd.read_parquet(p, columns=['user_id', 'url_host', 'date', ]) \\\n",
    "        .sort_values('date', kind='stable')\n",
    "    ds_part.groupby('user_id').apply(_add_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd9ed4-3491-4444-a02e-d2e78ceb14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('users_histories.txt', 'wt') as hists_file:\n",
    "    for h in users_histories:\n",
    "        hists_file.write(' '.join(map(str, list(h))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5afc9-a436-47a3-a47b-d3459c210a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open('users_histories.txt') as hists_file, joblib.Parallel(batch_size=1024, n_jobs=-1) as pool:\n",
    "    users_histories = pool(joblib.delayed(split_line)(line) for line in hists_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad5ccc-b6b1-4d44-b266-ce5227978da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_urls, interaction_counters = [], []\n",
    "with open('users_histories.txt') as hists_file:\n",
    "    for line in hists_file:\n",
    "        history = split_line(line)\n",
    "        urls, counts = np.unique(history, return_counts=True)\n",
    "        unique_urls.append(urls)\n",
    "        interaction_counters.append(counts)\n",
    "unique_urls = np.array(unique_urls, dtype=object)\n",
    "interaction_counters = np.array(interaction_counters, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d5a983-95c8-4f8c-862b-92e8e2af7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    'interactions_counters.npz', \n",
    "    unique_urls=unique_urls, interaction_counters=interaction_counters, \n",
    "    allow_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0d1b87-ff4b-4c7d-8ada-92f180ba3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_counters_file = np.load('interactions/interactions_with_counters.npz', allow_pickle=True)\n",
    "interactions_sets = interactions_counters_file['unique_urls']\n",
    "interactions_counters = interactions_counters_file['interaction_counters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337273e8-404c-495a-9e94-8c54e66d74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('interactions/interactions.npy', interactions_sets)\n",
    "np.save('interactions/interaction_counters.npy', interactions_counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d57735f-0dbd-4802-b2c2-71b04e2a43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_shares = np.array(\n",
    "    [cs / cs.sum() for cs in interactions_counters],\n",
    "    dtype=object\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d8a987-f807-49a2-8318-ccf13e2592b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('interactions/interaction_shares.npy', interactions_shares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f34d71-8613-4aec-988d-0b8dca3226c1",
   "metadata": {},
   "source": [
    "# URL normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f15645-076e-4883-9793-db81a76da0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short(url):\n",
    "    parts = url.split('.')\n",
    "    if len(parts) > 2 and len(parts[0]) == 1:\n",
    "        return '.'.join(parts[1:])\n",
    "\n",
    "    \n",
    "def remove_turbo(url):\n",
    "    if not url.endswith('turbopages.org') and not url.endswith('ampproject.org'):\n",
    "        return '.'.join(\n",
    "            p for p in url.split('.')\n",
    "            if p != 'amp'\n",
    "        )\n",
    "    parts = url.split('.')\n",
    "    if len(parts) == 2:\n",
    "        return url\n",
    "    return '.'.join(\n",
    "        (p or '-') \n",
    "        for p in parts[0].split('-')\n",
    "    ).replace('.-.', '-')\n",
    "\n",
    "\n",
    "def collapse_ips(url):\n",
    "    if url.startswith('192.168.'):\n",
    "        return '192.168.0.1'\n",
    "    return url\n",
    "\n",
    "\n",
    "normalizers = [remove_short, remove_turbo, collapse_ips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae2fd27-8418-4adb-b6bf-91693af8b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_domains = set(domains_numerator.cats)\n",
    "\n",
    "\n",
    "def normalize_url(url):\n",
    "    for norm in normalizers:\n",
    "        new_url = norm(url)\n",
    "        if new_url in known_domains:\n",
    "            url = new_url\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac925994-0566-48df-82f2-c6bdcb66f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_part_pass_set = {'localhost', 'chrome-extension'}\n",
    "\n",
    "\n",
    "def remove_one_part(url):\n",
    "    return (len(url.split('.')) > 1) or (url in one_part_pass_set)\n",
    "\n",
    "\n",
    "filters = [remove_one_part]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca0225f-9ae9-45b3-aaac-714841785835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_url(url):\n",
    "    return all(f(url) for f in filters)\n",
    "\n",
    "\n",
    "def map_url(url):\n",
    "    return domains_numerator.transform(normalize_url(url)) if check_url(url) else -1\n",
    "\n",
    "\n",
    "url_id_mapping = np.array(list(map(map_url, domains_numerator.cats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a9dded-7583-4f75-9ae4-05a729215634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_l2(url):\n",
    "    return '.'.join(url.split('.')[-2:])\n",
    "\n",
    "l2_domains = sorted({limit_l2(url) for url in domains_numerator.cats})\n",
    "l2_domains_indexes = {url: i for i, url in enumerate(l2_domains)}\n",
    "l2_domain_remapping = np.array([l2_domains_indexes[limit_l2(url)] for url in domains_numerator.cats] + [-1])\n",
    "\n",
    "url_id_mapping = l2_domain_remapping[url_id_mapping]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7323fc5f-e616-42c6-962e-f33794dc731a",
   "metadata": {},
   "source": [
    "# Matrix factorizaion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe35567-b745-41dd-9d66-809c53c966a5",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d691f0e9-fa51-4659-a010-3a8d525089b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0b02d7299349ae92fa79e880834e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users, domains, counts, dates = [], [], [], []\n",
    "for part in feature_utils.read_dir(converted_data_path):\n",
    "    users.append(part['user_id'].values)\n",
    "    domains.append(part['url_host'].values)\n",
    "    counts.append(part['request_cnt'].values)\n",
    "    dates.append(part['date'].values)\n",
    "users = np.concatenate(users)\n",
    "domains = np.concatenate(domains)\n",
    "counts = np.concatenate(counts)\n",
    "dates = np.concatenate(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98addd1e-12f5-4069-8994-4c3a2efbcc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = url_id_mapping[domains]\n",
    "\n",
    "retain_mask = domains != -1\n",
    "\n",
    "domains = domains[retain_mask]\n",
    "users = users[retain_mask]\n",
    "counts = counts[retain_mask]\n",
    "dates = dates[retain_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5dbf8-175c-4f28-9133-22d9beec7c97",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b329a7c3-66f7-43ec-8b94-a99251831731",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_interactions_matrix = sp.sparse.csr_matrix((counts, (users, domains)), shape=(n_users, n_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c9b9776-d25f-48e6-b6a4-2a7d69f8ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'factors': 256, \n",
    "    'iterations': 16, \n",
    "    'regularization': 50, \n",
    "    'alpha': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e398f68-975b-409f-87b8-6a2464467c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d14dcc22a754ac5bc856eb106778ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "als = implicit.als.AlternatingLeastSquares(calculate_training_loss=True, random_state=42, **params)\n",
    "als.fit(all_interactions_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87996311-0c78-4601-892d-211baaca3bbc",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f926d38-0f37-4741-a7a8-85183d6402ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_embeddings = als.user_factors.to_numpy()\n",
    "urls_embeddings = als.item_factors.to_numpy()\n",
    "\n",
    "timestamp = datetime.datetime.now()\n",
    "out_dir_path = embeddings_dir / f'als_l2_{timestamp:%m_%d_%H_%M}'\n",
    "%mkdir {out_dir_path}\n",
    "\n",
    "np.save(out_dir_path / 'users.npy', users_embeddings)\n",
    "np.save(out_dir_path / 'urls.npy', urls_embeddings)\n",
    "with open(out_dir_path / 'params.json', 'wt') as params_file:\n",
    "    json.dump(params, params_file)\n",
    "\n",
    "if 'url_id_mapping' in dir():\n",
    "    np.save(out_dir_path / 'url_mapping.npy', url_id_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba7f04-ee0a-45ff-87d4-388715708cdd",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4668817-01d6-4131-a5a0-30c2af275ac6",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772ede14-3024-4b1e-b245-ec7181a99e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "with open('users_histories.txt') as hists_file:\n",
    "    for line in hists_file:\n",
    "        history = split_line(line)\n",
    "        history = url_id_mapping[history]\n",
    "        history = history[history >= 0].tolist()\n",
    "        histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da5767-eb08-4d8d-a0fc-ea45c14cc42b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e260205c-abee-47d3-b259-425a3bb190a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now()\n",
    "model_dir = embeddings_dir / f'w2v_256_l2_{timestamp:%m_%d_%H_%M}'\n",
    "%mkdir {model_dir}\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(histories, workers=8, min_count=1, vector_size=256)\n",
    "w2v_model.save(f'{model_dir}/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3d969-0fd8-4e3a-b160-72d056d870c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model = word2vec.Word2Vec.load('embeddings/w2v_256')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d44e83-c4a9-486a-a291-903b3acbd0ce",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578d6381-d69c-4cfa-b6c0-6c69353b4cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipet-ru.turbopages.org\n",
      "massaget.kz\n",
      "normalnijhod.narod.ru\n",
      "lodki-motors.ru\n",
      "pugachevsky-site.ru\n",
      "elenadektereva.ru\n",
      "itznanie.ru\n",
      "vbassejn.ru\n",
      "zvezdagukovo.ru\n",
      "septik27-ru.turbopages.org\n"
     ]
    }
   ],
   "source": [
    "url = 'habr.com'\n",
    "url_id = domains_numerator.transform(url)\n",
    "\n",
    "for sim_id, _ in w2v_model.wv.most_similar(url_id):\n",
    "    print(domains_numerator.inv_transform(sim_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048b20c0-46ba-487f-8f56-9fe3632b7f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moeobrazovanie.ru\n",
      "russianblogs.com\n",
      "losst.ru\n",
      "itisgood.ru\n",
      "linuxconfig.org\n",
      "unity3d.ru\n",
      "pythonru.com\n",
      "python-scripts.com\n",
      "xn----dtbqbibcfgew1b.xn--p1ai\n",
      "gorndelo.ru\n"
     ]
    }
   ],
   "source": [
    "url = 'habr.com'\n",
    "url_id = l2_domains.index(url)\n",
    "\n",
    "for sim_id, _ in w2v_model.wv.most_similar(url_id):\n",
    "    print(l2_domains[sim_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a727f1a-c13d-4c01-99ab-e7d272339bf4",
   "metadata": {},
   "source": [
    "## User vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d3351-a676-4579-b62c-0d94d19874e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_counters = np.zeros(n_urls, np.int32)\n",
    "for history in histories:\n",
    "    np.add.at(url_counters, history, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3961c-36d3-48dc-acf8-26f6ebcc8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_weights = (np.minimum(url_counters, 100) / 100) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44e5dc-2618-4486-92b2-86f519b4edb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b766496ac44887b6baef4f67f5e7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/415317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 256\n",
    "\n",
    "def vectorize_user(user_history, weight=None, min_count=-1):\n",
    "    history_vectors = np.array(list(map(w2v_model.wv.get_vector, user_history)))\n",
    "    if min_count >= 0:\n",
    "        count_mask = url_counters[user_history] >= min_count\n",
    "        history_vectors = history_vectors[count_mask]\n",
    "    if len(history_vectors) == 0:\n",
    "        return np.zeros(dim)\n",
    "    if weight == 'norm':\n",
    "        history_weights = url_weights[user_history].reshape((-1, 1))\n",
    "        return (history_vectors * history_weights).mean(axis=0)\n",
    "    elif weight == 'weight':\n",
    "        history_weights = url_weights[user_history].reshape((-1, 1))\n",
    "        return (history_vectors * history_weights).sum(axis=0) / history_weights.sum()\n",
    "    else:\n",
    "        assert weight is None\n",
    "    return history_vectors.mean(axis=0)\n",
    "\n",
    "with joblib.Parallel(n_jobs=-1, batch_size=1024) as pool:\n",
    "    users_embeddings = pool(joblib.delayed(vectorize_user)(history) for history in tqdm(histories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "015826e2-96d0-4360-98dd-4118da045ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_embeddings = np.stack(users_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b80b4c-e2bd-4e96-a718-c59ee402e2ef",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21d3350a-a6e8-48ca-be7e-27ce883fd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_embeddings = np.stack([model.wv.get_vector(i) for i in range(n_urls)])\n",
    "# urls_embeddings = np.stack([w2v_model.wv.get_vector(i) for i in range(len(l2_domains))])\n",
    "\n",
    "np.save(f'{model_dir}/urls.npy', urls_embeddings)\n",
    "np.save(f'{model_dir}/users.npy', users_embeddings)\n",
    "if 'url_id_mapping' in dir():\n",
    "    np.save(model_dir / 'url_mapping.npy', url_id_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
